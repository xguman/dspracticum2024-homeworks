{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d253cf9b-d1df-497f-b4da-0198b09eee13",
   "metadata": {},
   "source": [
    "# HW03 Gradio app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b4233c6-048b-4c4b-8dc6-b2a993bfdb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in colab\n",
    "# !pip install -qq gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2a4dec-9d17-444f-883c-68f67ff25af9",
   "metadata": {},
   "source": [
    "## Load the model onto the CPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51471823-d010-4db1-b842-25768d1b4732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from fastai.vision.all import *\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the model\n",
    "learn = load_learner('./model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f17c1-39aa-4d74-b9d7-ab45036605cc",
   "metadata": {},
   "source": [
    "## Test it on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe7954e-e4c1-479b-b1f2-958ce14ea453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: bus\n",
      "Index of the predicted class: 1\n",
      "Probabilities: tensor([1.5081e-05, 9.9069e-01, 2.8906e-03, 7.3995e-05, 6.3293e-03])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace ## PATH TO SOME IMAGE ## with the actual file path of an image to test the model (e.g. some image from your test set)\n",
    "image_path = Path('/teamspace/studios/this_studio/data/transport_dataset/test/bus/image15.jpg')\n",
    "\n",
    "# Predict the class of the new image\n",
    "prediction, prediction_idx, probabilities = learn.predict(image_path)\n",
    "\n",
    "# Print the prediction result\n",
    "print(f'Prediction: {prediction}')\n",
    "print(f'Index of the predicted class: {prediction_idx}')\n",
    "print(f'Probabilities: {probabilities}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade4146-3ff2-4a45-85bb-a12858ea4f2e",
   "metadata": {},
   "source": [
    "## Run gradio locally\n",
    "\n",
    "Run the cell below to launch the Gradio interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a63ba1b-7f45-48ed-8912-b133027f1171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.1, however version 5.0.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on public URL: https://e60b97097a78950481.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e60b97097a78950481.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr  # Importing Gradio for creating the web interface\n",
    "\n",
    "# Extract categories (class labels) from the DataLoader\n",
    "categories = learn.dls.vocab\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(img):\n",
    "    pred, idx, probs = learn.predict(img)\n",
    "    return dict(zip(categories, map(float, probs)))  # Map categories to their probabilities\n",
    "\n",
    "# Define Gradio input and output components using the updated API\n",
    "image = gr.Image(width=224, height=224)  # Image input with fixed shape\n",
    "label = gr.Label()  # Output label to display classification\n",
    "examples = [image_path]  # Path to image(s) for demonstration\n",
    "\n",
    "# Create and launch the Gradio interface\n",
    "intf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)\n",
    "intf.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83965dc8-fd60-4462-87c4-96c3554960f3",
   "metadata": {},
   "source": [
    "## Deploy gradio app to ðŸ¤— space\n",
    "\n",
    "First, create a free [ðŸ¤— account](https://huggingface.co/) account and log in. In the top left corner, click '**NEW**', select **Space**, and fill out the short form. Choose *Gradio* for the *Space SDK* and make sure the space is set to *Public*. When your new space is created, select **Files** tab (top right corner). Now you should upload the following files into your space by clicking *Upload files*:\n",
    "\n",
    "  1. `model.pkl`: your model (trained in the previous notebook)\n",
    "  2. `requirements.txt`: list of the packages needed to run the space\n",
    "  3. `app.py`: the app itself\n",
    "  4. `test_image1.jpg`, `test_image2.jpg`: (optional) examples of images\n",
    "\n",
    "Except `model.pkl` and examples, you can get those files from https://github.com/simecek/dspracticum2024/tree/main/lesson03/gradio_app. Be sure to upload your `model.pkl`, and do not forget to check `app.py`. You will also need to modify examples `test_image1.jpg` and `test_image2.jpg`.\n",
    "\n",
    "When the files are uploaded, the app will start building (see status *Building*, then *Starting*, then *Running*). Once building is complete, select the **App** tab (next to the **Files** tab) to actually use the app. It should look similarly to https://huggingface.co/spaces/simecek/teaching_img_classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
